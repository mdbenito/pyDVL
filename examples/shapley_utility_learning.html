<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Data Utility Learning &mdash; pyDVL 0.1.1.dev1 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/design-tabs.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["\\(", "\\)"]], "processEscapes": true, "displayMath": [["\\[", "\\]"]]}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Influence functions for data mislabeling" href="influence_synthetic.html" />
    <link rel="prev" title="KNN Shapley" href="shapley_knn_flowers.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html">
            <img src="../_static/logo.svg" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                0.1
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Table of Contents</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../10-getting-started.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../20-install.html">Installing pyDVL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../30-data-valuation.html">Computing data values</a></li>
<li class="toctree-l1"><a class="reference internal" href="../40-influence.html">Computing influence values</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Examples</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="shapley_basic_spotify.html">Shapley for data valuation</a></li>
<li class="toctree-l2"><a class="reference internal" href="shapley_knn_flowers.html">KNN Shapley</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Data Utility Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="influence_synthetic.html">Influence functions for data mislabeling</a></li>
<li class="toctree-l2"><a class="reference internal" href="influence_wine.html">Influence functions and neural networks</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../pydvl/index.html">API Reference</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">pyDVL</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content style-external-links">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="index.html">Examples</a> &raquo;</li>
      <li>Data Utility Learning</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/examples/shapley_utility_learning.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
.jp-RenderedHTMLCommon table,
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.jp-RenderedHTMLCommon thead,
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.jp-RenderedHTMLCommon tr,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon td,
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.jp-RenderedHTMLCommon th,
div.rendered_html th {
  font-weight: bold;
}
.jp-RenderedHTMLCommon tbody tr:nth-child(odd),
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.jp-RenderedHTMLCommon tbody tr:hover,
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="admonition note">
    This page was generated from
    <a class="reference external" href="https://github.com/appliedAI-Initiative/pyDVL/blob/develop/notebooks/shapley_utility_learning.ipynb">notebooks/shapley_utility_learning.ipynb</a>
    <br>
    Interactive online version:
    <span style="white-space: nowrap;">
        <a href="https://mybinder.org/v2/gh/appliedAI-Initiative/pyDVL/develop?filepath=notebooks/shapley_utility_learning.ipynb">
            <img alt="Binder badge" src="https://mybinder.org/badge_logo.svg" style="vertical-align:text-bottom">
        </a>
    </span>
</div>

<style>
    .nbinput .prompt,
    .nboutput .prompt {
        display: none;
    }
</style><section id="Data-Utility-Learning">
<h1>Data Utility Learning<a class="headerlink" href="#Data-Utility-Learning" title="Permalink to this heading"></a></h1>
<p>This notebook introduces <strong>Data Utility Learning</strong>, a method of approximating Data Shapley values by learning to estimate the utility function.</p>
<p>The idea is to employ a model to learn the performance of the learning algorithm of interest on unseen data combinations (i.e. subsets of the dataset). The method was originally described in <em>Wang, Tianhao, Yu Yang, and Ruoxi Jia.</em><a class="reference external" href="https://doi.org/10.48550/arXiv.2107.06336">Improving Cooperative Game Theory-Based Data Valuation via Data Utility Learning</a><em>. arXiv, 2022</em>.</p>
<div class="admonition warning">
<p><strong>Warning:</strong> Work on Data Utility Learning is preliminary. It remains to be seen when or whether it can be put effectively into application. For this further testing and benchmarking are required.</p>
</div>
<p>Recall the definition of Shapley value <span class="math notranslate nohighlight">\(v_u(i)\)</span> for data point <span class="math notranslate nohighlight">\(i\)</span>:</p>
<p><span class="math">\begin{equation}
v_u(i) = \frac{1}{n} \sum_{S \subseteq N \setminus \{i\}} \binom{n-1}{|S|}^{-1} [u(S \cup \{i\}) − u(S)] ,
\tag{1}
\label{eq:shapley-def}
\end{equation}</span></p>
<p>where <span class="math notranslate nohighlight">\(N\)</span> is the set of all indices in the training set and <span class="math notranslate nohighlight">\(u\)</span> is the utility.</p>
<p>In Data Utility Learning, to avoid the exponential cost of computing this sum, one learns a surrogate model for <span class="math notranslate nohighlight">\(u\)</span>. We start by sampling so-called <strong>utility samples</strong> to form a training set <span class="math notranslate nohighlight">\(S_\operatorname{train}\)</span> for our utility model. Each utility sample is a tuple consisting of a subset of indices <span class="math notranslate nohighlight">\(S_j\)</span> in the dataset and its utility <span class="math notranslate nohighlight">\(u(S_j)\)</span>:</p>
<div class="math notranslate nohighlight">
\[\mathcal{S}_\operatorname{train} = \{(S_j, u(S_j): j = 1 , ..., m_\operatorname{train}\}\]</div>
<p>where <span class="math notranslate nohighlight">\(m_\operatorname{train}\)</span> denotes the <em>training budget</em> for the learned utility function.</p>
<p>The subsets are then transformed into boolean vectors <span class="math notranslate nohighlight">\(\phi\)</span> in which a <span class="math notranslate nohighlight">\(1\)</span> at index <span class="math notranslate nohighlight">\(k\)</span> means that the <span class="math notranslate nohighlight">\(k\)</span>-th sample of the dataset is present in the subset:</p>
<div class="math notranslate nohighlight">
\[S_j \mapsto \phi_j \in \{ 0, 1 \}^{N}\]</div>
<p>We fit a regression model <span class="math notranslate nohighlight">\(\tilde{u}\)</span>, called <strong>data utility model</strong>, on the transformed utility samples <span class="math notranslate nohighlight">\(\phi (\mathcal{S}_\operatorname{train}) := \{(\phi(S_j), u(S_j): j = 1 , ..., m_\operatorname{train}\}\)</span> and use it to predict instead of computing the utility for any <span class="math notranslate nohighlight">\(S_j \notin \mathcal{S}_\operatorname{train}\)</span>. We abuse notation and identify <span class="math notranslate nohighlight">\(\tilde{u}\)</span> with the composition <span class="math notranslate nohighlight">\(\tilde{u} \circ \phi : N \rightarrow \mathbb{R}\)</span>.</p>
<p>The main assumption is that it is much faster to fit and use <span class="math notranslate nohighlight">\(\tilde{u}\)</span> than it is to compute <span class="math notranslate nohighlight">\(u\)</span> and that for most <span class="math notranslate nohighlight">\(i\)</span>, <span class="math notranslate nohighlight">\(v_\tilde{u}(i) \approx v_u(i)\)</span> in some sense.</p>
<section id="Setup">
<h2>Setup<a class="headerlink" href="#Setup" title="Permalink to this heading"></a></h2>
<p>We begin by importing the main libraries and setting some defaults.</p>
<div class="admonition note">
<p>If you are reading this in the documentation, some boilerplate (including most plotting code) has been omitted for convenience.</p>
</div>
<p>As is the case with all other Shapley methods, the main entry point is the function <a class="reference internal" href="../pydvl/shapley.html#pydvl.shapley.compute_shapley_values"><span class="std std-ref">compute_shapley_values()</span></a>, which provides a facade to all algorithms in this family. We use it with the usual classes <a class="reference internal" href="../pydvl/utils/dataset.html#pydvl.utils.dataset.Dataset"><span class="std std-ref">Dataset</span></a> and <a class="reference internal" href="../pydvl/utils/utility.html#pydvl.utils.utility.Utility"><span class="std std-ref">Utility</span></a>. In addition, we must import the core class for learning a utility,
<a class="reference internal" href="../pydvl/utils/utility.html#pydvl.utils.utility.DataUtilityLearning"><span class="std std-ref">DataUtilityLearning</span></a>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pydvl.utils</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">Dataset</span><span class="p">,</span>
    <span class="n">Utility</span><span class="p">,</span>
    <span class="n">DataUtilityLearning</span><span class="p">,</span>
    <span class="n">top_k_value_accuracy</span><span class="p">,</span>
    <span class="n">available_cpus</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">pydvl.reporting.plots</span> <span class="kn">import</span> <span class="n">shaded_mean_std</span>
<span class="kn">from</span> <span class="nn">pydvl.shapley</span> <span class="kn">import</span> <span class="n">compute_shapley_values</span>
</pre></div>
</div>
</div>
</section>
<section id="Dataset">
<h2>Dataset<a class="headerlink" href="#Dataset" title="Permalink to this heading"></a></h2>
<p>Following the paper, we take 15 samples (10%) from the <a class="reference external" href="https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html">Iris dataset</a> and compute their Data Shapley values by using all the remaining samples as test set for computing the utility, which in this case is accuracy.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">Dataset</span><span class="o">.</span><span class="n">from_sklearn</span><span class="p">(</span>
    <span class="n">load_iris</span><span class="p">(),</span> <span class="n">train_size</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span> <span class="n">stratify_by_target</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<p>We verify that, as in the paper, if we fit a Support-Vector Classifier to the training data, we obtain an accuracy of around 92%:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">LinearSVC</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">x_train</span><span class="p">,</span> <span class="n">dataset</span><span class="o">.</span><span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Mean accuracy: </span><span class="si">{</span><span class="mi">100</span> <span class="o">*</span> <span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">x_test</span><span class="p">,</span> <span class="n">dataset</span><span class="o">.</span><span class="n">y_test</span><span class="p">)</span><span class="si">:</span><span class="s2">0.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Mean accuracy: 92.59%
</pre></div></div>
</div>
</section>
<section id="Data-Shapley">
<h2>Data Shapley<a class="headerlink" href="#Data-Shapley" title="Permalink to this heading"></a></h2>
<p>We start by defining the utility using the model and computing the exact Data Shapley values by definition <span class="math notranslate nohighlight">\(\ref{eq:shapley-def}\)</span>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">utility</span> <span class="o">=</span> <span class="n">Utility</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">dataset</span><span class="p">,</span> <span class="n">enable_cache</span><span class="o">=</span><span class="n">enable_cache</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">compute_shapley_values</span><span class="p">(</span>
    <span class="n">u</span><span class="o">=</span><span class="n">utility</span><span class="p">,</span>
    <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;combinatorial_exact&quot;</span><span class="p">,</span>
    <span class="n">n_jobs</span><span class="o">=</span><span class="nb">min</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">),</span> <span class="n">available_cpus</span><span class="p">()),</span>
    <span class="n">progress</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># Does not display correctly in a notebook</span>
<span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;data_value_std&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;data_value&quot;</span><span class="p">:</span> <span class="s2">&quot;exact&quot;</span><span class="p">})</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
2022-10-18 22:12:37,742 INFO worker.py:1509 -- Started a local Ray instance. View the dashboard at <span class="ansi-green-intense-fg ansi-bold">http://127.0.0.1:8265 </span>
</pre></div></div>
</div>
<p>We now estimate the Data Shapley values using the <a class="reference internal" href="../pydvl/utils/utility.html#pydvl.utils.utility.DataUtilityLearning"><span class="std std-ref">DataUtilityLearning</span></a> wrapper. This class wraps a <a class="reference internal" href="../pydvl/utils/utility.html#pydvl.utils.utility.Utility"><span class="std std-ref">Utility</span></a> and delegates calls to it, up until a given budget. Every call yields a utility sample which is saved under the hood for training of the given utility model. Once the budget is exhausted, <code class="docutils literal notranslate"><span class="pre">DataUtilityLearning</span></code> fits the model to the utility samples and all
subsequent calls use the learned model to predict the wrapped utility instead of delegating to it.</p>
<p>For the utility model we follow the paper and use a fully connected neural network. To train it we use a total of <code class="docutils literal notranslate"><span class="pre">training_budget</span></code> utility samples. We repeat this multiple times for each training budget.</p>
<div class="admonition note">
<p>Note how we use a MonteCarlo approximation instead of <code class="docutils literal notranslate"><span class="pre">combinatorial_exact</span></code> as before. This is because the exact computation samples subsets in a particular order, from the lowest size to the largest. Because the training budget for the model to learn the utility is around 1/4th of the total number of subsets, this would mean that we would never see utility samples for the larger sizes and the model would be biased (try it!)</p>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mlp_kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
    <span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
    <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span>
    <span class="n">solver</span><span class="o">=</span><span class="s2">&quot;adam&quot;</span><span class="p">,</span>
    <span class="n">learning_rate_init</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
    <span class="n">max_iter</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;Doing </span><span class="si">{</span><span class="n">n_runs</span><span class="si">}</span><span class="s2"> runs for each of </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">training_budget_values</span><span class="p">)</span><span class="si">}</span><span class="s2"> different training budgets.&quot;</span>
<span class="p">)</span>

<span class="n">pbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span>
    <span class="n">product</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_runs</span><span class="p">),</span> <span class="n">training_budget_values</span><span class="p">),</span>
    <span class="n">total</span><span class="o">=</span><span class="n">n_runs</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">training_budget_values</span><span class="p">),</span>
<span class="p">)</span>
<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">budget</span> <span class="ow">in</span> <span class="n">pbar</span><span class="p">:</span>
    <span class="n">pbar</span><span class="o">.</span><span class="n">set_postfix_str</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Run </span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2"> for training budget: </span><span class="si">{</span><span class="n">budget</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">dul_utility</span> <span class="o">=</span> <span class="n">DataUtilityLearning</span><span class="p">(</span>
        <span class="n">u</span><span class="o">=</span><span class="n">utility</span><span class="p">,</span> <span class="n">training_budget</span><span class="o">=</span><span class="n">budget</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">MLPRegressor</span><span class="p">(</span><span class="o">**</span><span class="n">mlp_kwargs</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="n">dul_df</span> <span class="o">=</span> <span class="n">compute_shapley_values</span><span class="p">(</span>
        <span class="n">u</span><span class="o">=</span><span class="n">dul_utility</span><span class="p">,</span>
        <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;truncated_montecarlo&quot;</span><span class="p">,</span>
        <span class="n">n_jobs</span><span class="o">=</span><span class="nb">min</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">),</span> <span class="n">available_cpus</span><span class="p">()),</span>
        <span class="n">progress</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">max_iterations</span><span class="o">=</span><span class="mi">2</span> <span class="o">**</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">),</span>  <span class="c1"># DUL will kick in after training_budget</span>
    <span class="p">)</span>
    <span class="n">dul_df</span> <span class="o">=</span> <span class="n">dul_df</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;data_value&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">budget</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">})</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df</span><span class="p">,</span> <span class="n">dul_df</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&quot;data_value_std&quot;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Doing 10 runs for each of 32 different training budgets.
</pre></div></div>
</div>
<p>Next we compute the <span class="math notranslate nohighlight">\(l_1\)</span> error for the different training budgets across all runs and plot mean and standard deviation. We obtain results analogous to Figure 1 of the paper, verifying that the method indeed works for estimating the Data Shapley values (at least in this context).</p>
<p>In the plot we also display the error we would incur if we used the mean of the exact values instead. Falling below this baseline provides a modicum of confidence that we are actually learning some signal.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">errors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">training_budget_values</span><span class="p">),</span> <span class="n">n_runs</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
<span class="n">accuracies</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">training_budget_values</span><span class="p">),</span> <span class="n">n_runs</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>

<span class="n">top_k</span> <span class="o">=</span> <span class="mi">3</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">budget</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">training_budget_values</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_runs</span><span class="p">):</span>
        <span class="n">y_true</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;exact&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
        <span class="n">y_estimated</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">budget</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">j</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
        <span class="n">errors</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">y_true</span> <span class="o">-</span> <span class="n">y_estimated</span><span class="p">,</span> <span class="nb">ord</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">accuracies</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">top_k_value_accuracy</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_estimated</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">top_k</span><span class="p">)</span>

<span class="n">error_from_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;exact&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span> <span class="o">-</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;exact&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="nb">ord</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_shapley_utility_learning_20_0.png" src="../_images/examples_shapley_utility_learning_20_0.png" />
</div>
</div>
<p>Let us next look at how well the ranking of values resulting from using the surrogate <span class="math notranslate nohighlight">\(\tilde{u}\)</span> matches the ranking by the exact values. For this we fix <span class="math notranslate nohighlight">\(k=3\)</span> and consider the <span class="math notranslate nohighlight">\(k\)</span> samples with the highest value according to <span class="math notranslate nohighlight">\(\tilde{u}\)</span> and <span class="math notranslate nohighlight">\(u\)</span>:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">shaded_mean_std</span><span class="p">(</span>
    <span class="n">accuracies</span><span class="o">.</span><span class="n">transpose</span><span class="p">(),</span>
    <span class="n">abscissa</span><span class="o">=</span><span class="n">training_budget_values</span><span class="p">,</span>
    <span class="n">mean_color</span><span class="o">=</span><span class="s2">&quot;dodgerblue&quot;</span><span class="p">,</span>
    <span class="n">shade_color</span><span class="o">=</span><span class="s2">&quot;lightblue&quot;</span><span class="p">,</span>
    <span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;$m_</span><span class="se">\\</span><span class="s2">operatorname</span><span class="si">{train}</span><span class="s2">$&quot;</span><span class="p">,</span>
    <span class="n">ylabel</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Average Top-</span><span class="si">{</span><span class="n">top_k</span><span class="si">}</span><span class="s2"> Accuracy&quot;</span><span class="p">,</span>
<span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_shapley_utility_learning_22_0.png" src="../_images/examples_shapley_utility_learning_22_0.png" />
</div>
</div>
<p>Finally, for each sample, we look at the distance of the estimates to the exact value across runs. Boxes are centered at the 50th percentile with wiskers at the 25th and 75th. We plot relative distances, as a percentage. We observe a general tendency to underestimate the value:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_shapley_utility_learning_25_0.png" src="../_images/examples_shapley_utility_learning_25_0.png" />
</div>
</div>
</section>
<section id="Evaluation-on-anomalous-data">
<h2>Evaluation on anomalous data<a class="headerlink" href="#Evaluation-on-anomalous-data" title="Permalink to this heading"></a></h2>
<p>One interesting way to assess the Data Utility Learning approach is to corrupt some data and monitor how the value changes. To do this, we will take the sample with the highest score and change its label.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">highest_value_index</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;exact&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">argmax</span><span class="p">()]</span>
<span class="n">y_train_corrupted</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">y_train</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">y_train_corrupted</span><span class="p">[</span><span class="n">highest_value_index</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">y_train_corrupted</span><span class="p">[</span><span class="n">highest_value_index</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span>
<span class="p">)</span> <span class="o">%</span> <span class="mi">3</span>

<span class="n">corrupted_dataset</span> <span class="o">=</span> <span class="n">Dataset</span><span class="p">(</span>
    <span class="n">x_train</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">x_train</span><span class="p">,</span>
    <span class="n">y_train</span><span class="o">=</span><span class="n">y_train_corrupted</span><span class="p">,</span>
    <span class="n">x_test</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">x_test</span><span class="p">,</span>
    <span class="n">y_test</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">y_test</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<p>We retrain the model on the new dataset and verify that the accuracy decreases:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">LinearSVC</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train_corrupted</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Mean accuracy: </span><span class="si">{</span><span class="mi">100</span> <span class="o">*</span> <span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">x_test</span><span class="p">,</span> <span class="n">dataset</span><span class="o">.</span><span class="n">y_test</span><span class="p">)</span><span class="si">:</span><span class="s2">0.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Mean accuracy: 82.96%
</pre></div></div>
</div>
<p>Finally, we recompute the values of all samples using the exact method and the best training budget previously obtained and then plot the resulting scores.</p>
<div class="admonition note">
<p>Notice the argument <code class="docutils literal notranslate"><span class="pre">enable_cache=False</span></code> when constructing <code class="docutils literal notranslate"><span class="pre">utility</span></code>: because we have changed some samples in the training set, the utility must be evaluated again on all possible subsets of samples.</p>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">best_training_budget</span> <span class="o">=</span> <span class="n">training_budget_values</span><span class="p">[</span><span class="n">errors</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">argmin</span><span class="p">()]</span>

<span class="n">utility</span> <span class="o">=</span> <span class="n">Utility</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">LinearSVC</span><span class="p">(),</span>
    <span class="n">data</span><span class="o">=</span><span class="n">corrupted_dataset</span><span class="p">,</span>
    <span class="n">enable_cache</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">df_corrupted</span> <span class="o">=</span> <span class="n">compute_shapley_values</span><span class="p">(</span>
    <span class="n">u</span><span class="o">=</span><span class="n">utility</span><span class="p">,</span>
    <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;combinatorial_exact&quot;</span><span class="p">,</span>
    <span class="n">n_jobs</span><span class="o">=</span><span class="nb">min</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">),</span> <span class="n">available_cpus</span><span class="p">()),</span>
    <span class="n">progress</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">df_corrupted</span> <span class="o">=</span> <span class="n">df_corrupted</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;data_value&quot;</span><span class="p">:</span> <span class="s2">&quot;exact&quot;</span><span class="p">})</span>

<span class="n">dul_utility</span> <span class="o">=</span> <span class="n">DataUtilityLearning</span><span class="p">(</span>
    <span class="n">u</span><span class="o">=</span><span class="n">utility</span><span class="p">,</span> <span class="n">training_budget</span><span class="o">=</span><span class="n">best_training_budget</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">MLPRegressor</span><span class="p">(</span><span class="o">**</span><span class="n">mlp_kwargs</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">dul_df</span> <span class="o">=</span> <span class="n">compute_shapley_values</span><span class="p">(</span>
    <span class="n">u</span><span class="o">=</span><span class="n">dul_utility</span><span class="p">,</span>
    <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;truncated_montecarlo&quot;</span><span class="p">,</span>
    <span class="n">n_jobs</span><span class="o">=</span><span class="nb">min</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">corrupted_dataset</span><span class="p">),</span> <span class="n">available_cpus</span><span class="p">()),</span>
    <span class="n">max_iterations</span><span class="o">=</span><span class="mi">2</span> <span class="o">**</span> <span class="nb">len</span><span class="p">(</span><span class="n">corrupted_dataset</span><span class="p">),</span>
    <span class="n">progress</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">dul_df</span> <span class="o">=</span> <span class="n">dul_df</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;data_value&quot;</span><span class="p">:</span> <span class="s2">&quot;estimated&quot;</span><span class="p">})</span>
<span class="n">df_corrupted</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df_corrupted</span><span class="p">,</span> <span class="n">dul_df</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_shapley_utility_learning_34_0.png" src="../_images/examples_shapley_utility_learning_34_0.png" />
</div>
</div>
<div class="admonition warning">
<p>As mentioned above, despite the previous results, this work is preliminary and the usefulness of Data Utility Learning remains to be tested in practice.</p>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="shapley_knn_flowers.html" class="btn btn-neutral float-left" title="KNN Shapley" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="influence_synthetic.html" class="btn btn-neutral float-right" title="Influence functions for data mislabeling" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022 AppliedAI Institute gGmbH.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>